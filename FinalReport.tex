%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Project Title : Parallel Methods in Linear Algebra
% Author        : Robert Pellegrin
% Date          : April 16, 2025
% Course        : MATH306 - Linear Algebra
% Instructor    : Dr. Spickler
% Description   : This document is the final report for the course project.
%                 It includes abstract, background, methods, results,
%                 and future work in standard research paper format.
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{titlesec}
\usepackage{graphicx} % For images
\usepackage{times} % For Times font
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{caption}
\usepackage{float}



% Header/Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}
\lhead{Final Project Report}

% Title formatting
\titleformat{\section}{\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesubsection}{1em}{}

\begin{document}

% Title Page
\begin{titlepage}
    \centering
    \vspace*{2in}
    {\Huge\bfseries Parallel Methods in Linear Algebra\par}
    \vspace{1in}
    {\Large Robert Pellegrin\par}
    \vspace{0.5in}
    {\large MATH 306\\ Dr.\ Spickler \\ \today\par}
    \vfill
\end{titlepage}

% Abstract
\newpage
\section*{Abstract}
This project explores the performance of serial and parallel implementations of two core linear algebra operations: \textbf{matrix multiplication}
and \textbf{LU decomposition}. These algorithms were implemented in both C++ and Rust, allowing for a comparison of not only parallel speedup but
also language-level performance differences. The matrix multiplication was done using the standard three-loop algorithm, while LU decomposition
was implemented with partial pivoting and rounding of very small values to zero to reduce numerical errors.

\parskip=1em

Parallel versions were created using OpenMP in C++ and the Rayon library in Rust, both of which enable shared-memory parallelism with minimal
code changes. Performance testing was conducted on square matrices of increasing sizes, with execution times recorded and averaged across
multiple runs to ensure consistency. The results were then analyzed to evaluate the benefits of parallelism and to compare how each language
handles high-performance numerical computing tasks.

\parskip=1em

By benchmarking both serial and parallel variants in each language, this project aims to provide insights into the trade-offs between ease of
implementation, execution speed, and scalability when working with computationally intensive linear algebra algorithms.

% Begin main content
\section{Background and Motivation}
Linear algebra is incredibly important in computer science and related fields, from graphics and machine learning to scientific simulations.
Two common but computationally intensive tasks in linear algebra are matrix multiplication and LU decomposition. Matrix multiplication is fundamental
in areas like computer graphics, graph theory, and neural networks, while LU decomposition helps us solve systems of equations
efficiently---something critical in science, engineering, and computing.

\parskip=1em

Even though these operations are conceptually straightforward, performing them on large matrices can become extremely slow when using a simple,
one-step-at-a-time (serial) approach. As the amount of data gets bigger, serial implementations of these algorithms can become too slow to remain practical. This is
where parallel computing becomes interesting---by running computations simultaneously on a multi-core CPU, we can potentially
achieve big improvements in speed.

\parskip=1em

This project focuses on implementing and comparing serial and parallel versions of matrix multiplication and LU decomposition. Specifically,
I'm using two popular programming languages: C++ and Rust. C++ has long been favored for performance-sensitive tasks because it offers powerful
tools for optimization. Rust, though newer, has gained popularity due to its built-in safety features and strong performance, sometimes outperforming
older languages in efficiency and speed.

\parskip=1em

By writing and benchmarking serial and parallel versions of these algorithms in both languages, the goal is to answer two key questions:

\begin{itemize}
    \item How much faster are parallel versions of these algorithms compared to their serial counterparts?
    \item Does the choice of programming language (C++ versus Rust) significantly impact the performance?
\end{itemize}

This comparison is useful because, as computing increasingly moves toward multi-core processors, it's essential to know which languages and methods can
best take advantage of this hardware. The results could help guide decisions in future projects, especially when performance is critical.


\section{Methods \& Tools}

This project involved implementing two fundamental linear algebra algorithms---\textbf{matrix multiplication} and \textbf{LU decomposition}---in both
serial and parallel forms, using two different programming languages: \textbf{C++} and \textbf{Rust}. The goal was to explore not only how parallelism
improves performance, but also how the choice of language affects execution time and overall efficiency.

\subsection*{Matrix Multiplication}

Matrix multiplication in this project was implemented using the standard algorithm involving three nested loops. Given two matrices, \( A \) and \( B \),
the resulting matrix \( C \) is computed such that each element \( C_{ij} \) is the sum of products between the elements in the \( i \)-th row of \( A \)
and the \( j \)-th column of \( B \):

\[
    C_{ij} = \sum_{k=1}^{n} A_{ik} \times B_{kj}
\]

The standard matrix multiplication algorithm has a time complexity of \( \mathcal{O}(n^3) \), where \( n \) is the size of the square matrices.
This cubic growth causes runtime to increase rapidly as matrix size increases, making parallelization especially important for maintaining reasonable
performance at larger scales.

To address this challenge, a parallel version of the algorithm was implemented by distributing the outer loop (which iterates over the rows of the
result matrix) across multiple threads. In C++, parallelization was achieved using \textbf{OpenMP}, which simplifies loop-level parallelism through
the \texttt{\#pragma omp parallel for} directive. In Rust, the \textbf{Rayon} library was used to safely and efficiently parallelize iteration using
the \texttt{par\_iter()} API.

The algorithm was tested on square matrices of various sizes (e.g., \(100 \times 100\), \(500 \times 500\), \(1000 \times 1000\), etc.), and execution
times were recorded to observe how performance scaled with input size and to evaluate the speedup achieved by the parallel implementations compared to
their serial counterparts.

\subsection*{LU Decomposition}
The LU decomposition algorithm with partial pivoting has a time complexity of \( \mathcal{O}(n^3) \), where \( n \) is the size of the square matrix.
This complexity arises from the nested loop structure used to eliminate entries below the main diagonal and construct the lower and upper triangular matrices.
As matrix size increases, the computational cost becomes substantial, making parallelization of the elimination phase especially valuable.

LU decomposition factors a matrix \( A \) into the product of a lower triangular matrix \( L \) and an upper triangular matrix \( U \). When partial
pivoting is introduced to improve numerical stability, the factorization becomes \( PA = LU \), where \( P \) is a permutation matrix representing the
row swaps made during the decomposition. Partial pivoting helps avoid divisions by small pivot values, which can otherwise lead to large rounding errors
in floating-point arithmetic.

To further mitigate floating-point inaccuracies, a small threshold (e.g., \(1 \times 10^{-10}\)) was applied to round very small computed values to zero.
This helps reduce numerical noise introduced during real-number computations and ensures cleaner results.

Parallelizing LU decomposition is more complex than matrix multiplication due to data dependencies between rows, especially during pivot selection and row
elimination. In the parallel implementation, the row elimination steps that follow each pivot selection were parallelized. In C++, \textbf{OpenMP} was used
to distribute inner loop computations across threads. In Rust, \textbf{Rayon} was used to parallelize row operations using safe, efficient iterators.
Synchronization was carefully managed to avoid race conditions when updating shared structures such as pivot rows or performing row swaps.

Although more advanced or block-based LU algorithms with improved cache utilization exist, the classical method with partial pivoting was selected for this
project due to its simplicity and suitability for evaluating serial and parallel implementations in both C++ and Rust.


\subsection*{Languages \& Libraries}

I chose \textbf{C++} for its long-standing reputation in high-performance computing, and \textbf{Rust} for its modern design, strong memory safety guarantees,
and native support for concurrency. The tools and libraries used include:

\begin{itemize}
    \item \textbf{C++}
          \begin{itemize}
              \item GCC compiler with optimization flags (\texttt{-O2}, \texttt{-fopenmp})
              \item OpenMP for parallelism
              \item \texttt{chrono} library for timing
          \end{itemize}

    \item \textbf{Rust}
          \begin{itemize}
              \item Stable Rust compiler (\texttt{cargo})
              \item Rayon crate for data-parallelism
              \item \texttt{std::time::Instant} for timing
          \end{itemize}
\end{itemize}

Both versions of the code were tested on the same machine to ensure consistent comparisons. I also wrote basic matrix generators and along with various
sanity-checking functions to verify the correctness of the algorithms by comparing outputs from serial and parallel versions.

To ensure fair and efficient performance comparisons, compiler optimizations were enabled for both C++ and Rust builds. For the C++ programs,
optimization flags -O2 and -fopenmp were used with the GCC compiler to improve execution speed and enable parallelization via OpenMP.
In Rust, programs were compiled using the --release flag, which enables aggressive optimizations through LLVM, resulting in significantly faster
runtime performance compared to (default) debug builds. These optimizations were necessary for obtaining realistic benchmark results, particularly when
comparing serial and parallel execution times across both languages.

\subsection*{Performance Measurement}

Execution time was the primary metric used to compare the performance of different implementations. Each program was run multiple times, and the average
runtime was recorded to minimize variance caused by system processes or hardware interruptions. Results were organized in tables and plotted to visualize
the differences between serial and parallel execution, as well as between C++ and Rust implementations.

To help automate the benchmarking process, I wrote a Bash script that incrementally increased the matrix size passed to each program. This script looped
through a range of sizes (e.g., from 100 to 10000, increasing by 100 each time), called the appropriate executable, and captured the runtime output.
Automating this step not only ensured consistency across runs but also made it easier to test a broad range of input sizes without manually rerunning
each test.

\section{Results}
Discuss findings, show some figures, tables, and/or code snippets.
Explain results in context stated goals.
% Code for figures. Graphs of timings may go here.
% \newpage
% \section*{Figures}
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.8\textwidth]{figure1.png}
%     \caption{Figure caption here}
%     \label{fig:figure1}
% \end{figure}


\section{Summary and Future Work}
While this project focused on matrix multiplication and LU decomposition, there are many other linear algebra algorithms that could benefit significantly
from parallelization. Expanding the scope of this work to include additional algorithms would offer a more comprehensive understanding of where parallel
computing provides the most value in scientific and mathematical computing.

\parskip=1em

One natural extension would be to explore \textbf{QR decomposition} and \textbf{Cholesky decomposition}, both of which are used in numerical analysis,
machine learning, and solving systems of equations. These algorithms involve matrix transformations that are computationally intensive and contain
steps that could be parallelized similarly to LU decomposition. Another candidate is the \textbf{Singular Value Decomposition (SVD)}, which is widely
used in data science and dimensionality reduction. Although more complex, it presents a great opportunity for parallel optimization due to the large number
of operations involved.

\parskip=1em

Beyond algorithm selection, there are also more advanced parallelization techniques that could be explored. In this project, shared-memory
parallelism was used via OpenMP in C++ and the Rayon library in Rust. However, these approaches are limited by the number of CPU cores available.
To push performance further, especially for large matrix sizes, \textbf{GPU acceleration} using technologies like \textbf{NVIDIA CUDA} could be
highly effective. GPUs are well-suited for linear algebra due to their high number of processing cores and fast context switching, allowing massive
numbers of computations to run in parallel.

\parskip=1em

In the Rust ecosystem, GPU programming is still emerging, but there are crates like \texttt{cust} (a CUDA wrapper) that can be used to write Rust
programs that run directly on the GPU. Exploring how GPU-based matrix operations in Rust compare to traditional CPU-based ones would be a valuable
next step. Similarly, \textbf{SIMD} (Single Instruction, Multiple Data) is another performance optimization strategy worth considering. SIMD allows
a single instruction to operate on multiple data points at once, which is perfect for vector and matrix computations. Rust has libraries like
\texttt{wide} and \texttt{std::simd} (which is still in development) that provide abstractions for SIMD programming and could significantly boost the
performance of both serial and parallel implementations.

\parskip=1em

Another area of interest would be to look at \textbf{distributed computing} approaches for extremely large datasets that don't fit into memory on a
single machine. While this project didn't include MPI, revisiting distributed memory parallelism could provide insight into scaling linear algebra computations beyond a single workstation.

\parskip=1em

Lastly, deeper numerical accuracy analysis and profiling could be explored. Comparing how different languages and approaches handle
floating-point errors or identifying performance bottlenecks at the instruction level using profiling tools like \texttt{gprof}, \texttt{perf}, or
Rust's \texttt{flamegraph} crate could provide more technical depth and further guide optimization efforts.

\parskip=1em

In summary, while this project lays a solid foundation for understanding parallelism in matrix operations, there is much room for future work in exploring
additional algorithms, more advanced hardware acceleration techniques, and deeper performance analysis.


% Begin Bibliography
\newpage
\begin{thebibliography}{9}
    \bibitem{openmpSpec2020}
    OpenMP Architecture Review Board, \textit{OpenMP Application Programming Interface Version 5.1},
    \url{https://www.openmp.org/specifications/}, 2020.

    \bibitem{rayonGitHub}
    Niko Matsakis and Rayon Contributors, \textit{Rayon: A data parallelism library for Rust},
    \url{https://github.com/rayon-rs/rayon}, Accessed 2025.

    \bibitem{rayonDocs}
    Rayon Contributors, \textit{Rayon Crate Documentation}, \url{https://docs.rs/rayon/latest/rayon/}, Accessed 2025.
\end{thebibliography}

\end{document}
